{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94780e0f",
   "metadata": {},
   "source": [
    "# Working with Planet Data a.k.a Programmatic Adventures in Image Filtering\n",
    "\n",
    "The aim of this Notebook is to help familiarize you with ways to start filtering Plant data using their API. This notebook is divided into two parts. In the first part, we will focus on the first phase of a larger research project: you have picked a few small study areas, and are likely wanting to build a time series of images for an area that you'll usef for classification, machine learning, deriving phenology, etc. Dealing with the challenges of identifying suitable images for your pilot study area is the focus of the first part of this notebook.\n",
    "\n",
    "In the second part of this notebook, we will look at the second phase of a larger study. Having conducted a proof of concept study for several locations, you are now wanting to apply your methods to a larger study area. While the filtering techniques are similar, there are some different challenges you will face when working with larger spatial extents. Dealing with those challenges is the focus of the second half of the notebook.\n",
    "\n",
    "Let's dive in!\n",
    "\n",
    "This document is adapted from Planet's `search_and_download_quickstart.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf45e519",
   "metadata": {},
   "source": [
    "## Note - Why programmatic image filtering\n",
    "\n",
    "There are many reasons for starting to deal with your data programmatically. One good reason is that it helps contributes to both open and repeatable science! That is certainly a worthy and worthwhile endevour. On the the practical side of research: when the volume of data is so large, working programmatically is the only way you will manage to be effective and efficient with your research. Why?\n",
    "\n",
    "[Welcome to the world of constellations of satellite platforms and sensors](https://www.planet.com/our-constellations/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163d8e04",
   "metadata": {},
   "source": [
    "## Part 1 - Image filtering for smaller areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29d4e2d",
   "metadata": {},
   "source": [
    "First step we are going to load the libraries we will be working with today. Hopefully that is straightforward. If not, ask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3247b60",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f148d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import json\n",
    "import time\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon, shape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2b5d6",
   "metadata": {},
   "source": [
    "### set working paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6568f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'iDir' : 'boundaries/',\n",
    "    'oDir' : 'imagery/'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb60c4e4",
   "metadata": {},
   "source": [
    "### define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_geojson(file_path):\n",
    "    '''Function to open a GeoJSON file given a path.'''\n",
    "    with open(file_path) as f:\n",
    "#         gj = geojson.load(f)\n",
    "        gj = json.load(f)\n",
    "        \n",
    "    return gj\n",
    "\n",
    "def get_geojson_geometry(geojson):\n",
    "    '''Function to extract the geometry attribute from a GeoJSON object '''\n",
    "    geometry = [i['geometry'] for i in geojson['features']]\n",
    "    \n",
    "    return geometry\n",
    "\n",
    "def plot_wrapper(gdf, ax, color, linewidth=1.5):\n",
    "    '''Convenience function for overlaying spatial data on the same plot'''\n",
    "    gdf.plot(\n",
    "        facecolor=\"none\",\n",
    "        edgecolor=color,\n",
    "        linewidth=linewidth,\n",
    "        ax = ax   \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e322380d",
   "metadata": {},
   "source": [
    "## Part 1 - Filtering for a pilot area of interest (AOI)\n",
    "\n",
    "The steps we're going to follow here are:\n",
    "   1. Load the data for our AOI\n",
    "   1. Convert the data to a GeoDataFrame\n",
    "   1. Examine the structure of a Planet API query\n",
    "   1. Load results of a previously query \n",
    "   1. Convert results to a GeoDataFrame\n",
    "   1. Filter! \n",
    "\n",
    "### Load the AOI data - GeoJSON\n",
    "\n",
    "A GeoJSON is one of the many geospatial data formats. It is a more modern format, that many geospatial analysts are not familiar with. In some ways, it's broadly similar to an ESRI shapefile.\n",
    "\n",
    "One noticable difference between a shapefile and a GeoJSON is the cooridnate reference system and projections. Whereas shapefiles support may different CRS and projections, GeoJSON only supports geographic coordinates. Yes, that is right. WGS84 Geographic is only CRS and coordinate system GeoJSON supports.\n",
    "Western Minnesota study area\n",
    "\n",
    "The area we will be using for this Notebook is focused on the western areas of Minnesota. This is farm country, and the GeoJSON contains two small farm fields that represnt the Area of Interest (AOI) for this study.\n",
    "\n",
    "But first, here is a bit of an exploration of the GeoJSON format. Once imported, you'll note that its a MultiPolygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "west_mn = open_geojson('./' + paths['iDir'] + 'western_mn.geojson')\n",
    "west_mn = get_geojson_geometry(west_mn)\n",
    "west_mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69cb37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms = [Polygon(west_mn[0]['coordinates'][i][0]) for i in range(len(west_mn[0]['coordinates']))]\n",
    "\n",
    "aoi = gpd.GeoDataFrame(\n",
    "    {'fields' : ['51', '46'], 'vals' : [10, 20] },\n",
    "    geometry = geoms,\n",
    "    crs = 4326\n",
    ")\n",
    "aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5dcf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c4532",
   "metadata": {},
   "source": [
    "### Structure of Planet query\n",
    "\n",
    "Some key componets of the a query to the Planet API:\n",
    "   1. API key. Basically this is your authorization credential for accessing and downloading data.\n",
    "   1. Base URL. You interface with the API via the web. The base URL is the site you are interacting with\n",
    "   1. Filter paramters. Several are required, and are likely familiar:\n",
    "       1. Geometric filter - Spatially constrain the search\n",
    "       1. Date & time filter - Temporal constraints on the search\n",
    "       1. Cloud filter - Constrain results using cloud thresholds\n",
    "       1. Combined filter - A filter that combines the above filters using boolean logic\n",
    "       1. Item type filter - The Planet Image product you are after\n",
    "       \n",
    "       \n",
    "Anatomy of a query:\n",
    "\n",
    "#### API Key\n",
    "Provided by Planet. Keys are usually a unique sting:\n",
    "    e.g. key : `123veryweakkey456`\n",
    "\n",
    "#### Geometric filter\n",
    "```\n",
    "geojson_geometry = west_mn[0]\n",
    "\n",
    "# get images that overlap with our AOI \n",
    "geo_filter = {\n",
    "  \"type\": \"GeometryFilter\",\n",
    "  \"field_name\": \"geometry\",\n",
    "  \"config\": geojson_geometry\n",
    "}\n",
    "```\n",
    "\n",
    "#### Date & time filter\n",
    "```\n",
    "# get images acquired within a date range\n",
    "date_filter = {\n",
    "  \"type\": \"DateRangeFilter\",\n",
    "  \"field_name\": \"acquired\",\n",
    "  \"config\": {\n",
    "    \"gte\": \"2021-05-25T00:00:00.000Z\",\n",
    "    \"lte\": \"2021-05-25T23:59:59.000Z\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Cloud filter\n",
    "```\n",
    "cc_filter = {\n",
    "  \"type\": \"RangeFilter\",\n",
    "  \"field_name\": \"cloud_cover\",\n",
    "  \"config\": {\n",
    "    \"lte\": 0.0\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Combined Filter\n",
    "```\n",
    "combined_filter = {\n",
    "  \"type\": \"AndFilter\",\n",
    "  \"config\": [geo_filter, date_filter, cc_filter]\n",
    "}\n",
    "```\n",
    "\n",
    "#### Item type\n",
    "```\n",
    "item_type = \"PSScene\"\n",
    "# API request object\n",
    "search_request = {\n",
    "  \"item_types\": [item_type], \n",
    "  \"filter\": combined_filter\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e3a94a",
   "metadata": {},
   "source": [
    "### Putting the query together:\n",
    "```\n",
    "search_result = \\\n",
    "  requests.post(\n",
    "    'https://api.planet.com/data/v1/quick-search',\n",
    "    auth=HTTPBasicAuth(PLANET_API_KEY, ''),\n",
    "    json=search_request)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581060d5",
   "metadata": {},
   "source": [
    "## Processing seach return\n",
    "\n",
    "Planet will return a JSON object. Let's load the results of the query and have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f70bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/pilot_query.json', 'r', encoding='utf-8') as f:\n",
    "    results_json = json.load(f)\n",
    "\n",
    "results_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e92186",
   "metadata": {},
   "source": [
    "Convert this to a DataFrame. JSON is good for transit across the web, but not for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = pd.json_normalize(results_json['features'], max_level=1)\n",
    "\n",
    "# rename properties column, dropping the properties label\n",
    "prop_cols = {col: col.split('.')[1] for col in tiles.columns if 'properties' in col}\n",
    "tiles.rename(columns=prop_cols, inplace=True)\n",
    "tiles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5d654",
   "metadata": {},
   "source": [
    "### Convert the results to a GeoDataFrame\n",
    "Getting to a DataFrame is useful. Some of the filtering we are going to do now can be accomplished using the metadata alone. More useful however, will be to make this a GeoDataFrame. Once we have a GeoDataFrame, we will then be able to make use of spatial operations as well as traditional filtering.\n",
    "\n",
    "In order to use some additional filtering logic, we're going to convert the information about the returned tiles to a geopandas GeoDataFrame. To do that, we need to add information about the geometry. That was returned to us in the JSON object (geometry.coordinates) and all we need to do is tell geopandas about the geometry. In this case it's a Polygon, so we'll use the Polygon object from shapely to define it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e184bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms = [Polygon(geo[0]) for geo in tiles['geometry.coordinates']]\n",
    "tiles = gpd.GeoDataFrame(tiles, geometry = geoms, crs=4326)\n",
    "tiles['centroids'] = tiles['geometry'].centroid\n",
    "tiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec010dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = tiles.explore( color ='orange', style_kwds={'stroke': True, 'fill': False})\n",
    "aoi.explore( color= 'blue', m = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a010d88",
   "metadata": {},
   "source": [
    "Let's have a look at what sensor types were returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1acdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = set(tiles['instrument'])\n",
    "instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230aa6fa",
   "metadata": {},
   "source": [
    "### Sensor type\n",
    "\n",
    "Over time, Planet has improved and evolved the sensors comprising their satelite constilations. Depending on what sensors were passing over, you may find that sensor type is able to reduce the number of tiles. As can be seen, there are two sensor types returned in the above: 'PS2.SD', 'PSB.SD'. These types are described in detail by Planet.\n",
    "\n",
    "Of revlevence the PS2.SD is the second generation of the Planet Scope line, and PSB.SD is the third generation of their Planet Scope Sensor. Depending on the time frame for your study, not all of the sensor types will be available, and may not provide a useful filtering option.\n",
    "\n",
    "You'll see in the above, there is only one PS2.SD tile, but since that is an older generation sensor, it would be a decent option if it were the ony tile availabe. But seeing as there are 18 tiles from the newer generation, we filter on PSB.SD and then look at other options for filtering down.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = tiles[tiles.instrument=='PSB.SD']\n",
    "tiles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f95c9",
   "metadata": {},
   "source": [
    "###  Find tiles that contain the AOI\n",
    "\n",
    "Alhough there are a lot of footprints in the figure above, particularly for the PS2.SD insturmnets, if you look at the left most of the blue AOI polygons, you will notice that it is bisected by several of the footprints. One way to filter tiles down is to identfy only those tiles that contain the AOI.\n",
    "\n",
    "Looking for tiles that contain an AOI will not always prove useful. In the next section the focuses will be on larger study areas, the AOI is large, spaning several different satellite overpass tracks. Containment by tile footprints will not be useful in that instance. If you have several locations that are close together (as in this instance), it can be useful. Having all of your close together AOIs observed by a single sensor means can help ensure variablity in the AOIs is a function of actual variablity. In the older generations of sensors, there was much more radiometric variability in the insturments, and having all of your AOIs in one tile helped to ensure that variability in the AOI was a function of what was happening on the ground, and not an artifact of being observed by different platforms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f6592",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_contain_aoi = gpd.sjoin(tiles, aoi,  how='inner', predicate='contains' )\n",
    "# tiles_contain_aoi = gpd.sjoin(aoi, tiles, how='inner', predicate='within')\n",
    "\n",
    "# tiles_contain_aoi = tiles.sjoin(aoi, how='inner', predicate='contains')\n",
    "tiles_contain_aoi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd1b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_contain_aoi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218e26b",
   "metadata": {},
   "source": [
    "Now, instead of a data frame with 18 tiles, we have one with 27! What is going on?\n",
    "\n",
    "Basically, since the AOI is composed of multiple polygonds, each tile has to determine whether or not it containes each of the AOI shapes by itself. a check for whether or not it contains the shape independently. What we end up with is a dataframe that has repeated rows. That is, the result after sjoin is we have all of the rows that either contained either the left field, or the right field.\n",
    "\n",
    "What we want to do is identify the fields where both left and right were contained. This becomes a bit clearer, when we look at the indexex of the resulting dataframe. Notice that their are repeated index values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_contain_aoi.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3450e1",
   "metadata": {},
   "source": [
    "We can use the `duplicated()` method to identy which ones are repeated. By using the `keep=False` we can see which of the values is not repeated. So looks like there is only one value that is not repeated. This indicates that of all the Planet tiles that contain the left field, only one does not also contain the right field.\n",
    "\n",
    "We can use this fact to generate the unique set of fields that contain both fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_contain_aoi.index.duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe96c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tiles_contain_aoi.index.duplicated(keep=False)\n",
    "idx = list(set(tiles_contain_aoi.loc[idx].index))\n",
    "idx, len(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04486687",
   "metadata": {},
   "source": [
    "We can now see, that of our 18 tiles captured by our preferred Planet constillation, there are 13 tiles that contain both fields. To confirm this we'll use the index values to regenerate the `tiles_contain_aoi` to represent only the unique tiles that actually contain both fields.\n",
    "\n",
    "Before we do that, we will use the indexes of the contained tiles to show that this list is only tiles that contain both fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in idx:\n",
    "    ax = tiles[tiles.index==i].plot(edgecolor='orange', facecolor='none')\n",
    "    aoi.plot(edgecolor='blue', facecolor='blue', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd58ebc",
   "metadata": {},
   "source": [
    "And we can also use the indexes to plot the tiles that didn't contain both, just as a double check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tiles[~tiles.index.isin(idx)].index:\n",
    "    ax = tiles[tiles.index==i].plot(edgecolor='red', facecolor='none')\n",
    "    aoi.plot(edgecolor='blue', facecolor='blue', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523215f0",
   "metadata": {},
   "source": [
    "Now, we'll use those indexes to subset the tiles dataframe so that it only contains those tiles that contained both fields. This is preferable to working with the original tiles_contain_aoi generated with the `.sjoin()` method, as it will not contain duplicated tiles. When it comes to actually ordering and downloading tiles from Planet, the aim is to avoid duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ecbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_contain_aoi = tiles[tiles.index.isin(idx)]\n",
    "tiles_contain_aoi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5055d5",
   "metadata": {},
   "source": [
    "Thirteen images is still a lot of duplicated data. While we might want a such a dense time series if we were wanting to examine the ways in which satellite overpass, view angle angle, and geometry of incident solar radiation impacted the observation values, this might be ok.\n",
    "\n",
    "### Acquistion time\n",
    "\n",
    "But in this case, we'll use the aquisition time to filter out additional files. To do so, we will have a closer look at the acquired field.\n",
    "\n",
    "Ideally, what we would like are images that were aquired close to solar noon. But in looking at those dates, it seems we have a problem in that the hour are 16, 17 which look to be potentially ~4 - 5 hours after noon. If that were true, it would not be very convenient.\n",
    "\n",
    "Note that the `dtype` of the column is `object`. What we really want is a `datetime` object. Also note that the values all end in a `Z`. This is in part because the Planet data are collected in UTC time, which means that the apparently 4-5 hour difference between solar noon is wrong. So, let's set change this to a `datetime` object, and then change the timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_contain_aoi['acquired']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca11bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_contain_aoi['acquired'] = pd.to_datetime(tiles_contain_aoi['acquired'], utc=True)\n",
    "tiles_contain_aoi['acquired'] = tiles_contain_aoi['acquired'].dt.tz_convert('US/Central')\n",
    "tiles_contain_aoi['acquired']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951add7",
   "metadata": {},
   "source": [
    "During the time of year that we're exploring, UTC is 5 hours ahead of US/Central time. To idenfity the image closest to solar noon, we'll need to create a time variable for comparison.\n",
    "\n",
    "To do that, we will use the date portion of the Datetime object from the first row in our dataframe. Since this dataframe only has images from a single date, we could have manually set the `solar noon` variable in this instance. However, this code block below shows you how to set it semi-programatically. That is, the date portion of the object is extracted from an entry in the table, and the time and time zone are then hardcoded/\n",
    "\n",
    "There are likely ways to set the time programatically, depending on your locatation. Hopefully, you are not trying to do this for AOIs that span multiple time-zones. If you are, you probably want to rethink your filtering approach. Even if you set both the date and time programmatically, it's likely to become messy trying time to filter your tile list down when dealing with areas that span multiple time zones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3042316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_noon = tiles_contain_aoi.loc[0]['acquired'].strftime(\"%Y-%m-%d\")\n",
    "solar_noon = pd.to_datetime(f'{solar_noon}T17:00:00', utc=True).tz_convert('US/Central')\n",
    "# solar_noon = pd.to_datetime(np.datetime64(f'{solar_noon}T15:00:00'))#.dt.tz_conver('US/Central')\n",
    "solar_noon#.dt.tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48389db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diff = tiles_contain_aoi['acquired'] - solar_noon\n",
    "np.abs(time_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_idx = time_diff[np.abs(time_diff) == np.abs(time_diff).min()].index\n",
    "min_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_contain_aoi.loc[min_idx]['id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_contain_aoi.loc[min_idx]['assets'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a001f61",
   "metadata": {},
   "source": [
    "## Part 2 - Filtering for large spatial exents\n",
    "\n",
    "Some of the steps in the next section of the notebook will look familiar. We just practiced them above. However, working with larger spatial extents has some specific challenges. We will explore those in this section.\n",
    "\n",
    "#### Twin Cities Metro Area\n",
    "\n",
    "The area we will be using for this section is focused on the Twin Cities Metro area. We'll start by loading the file. Once loaded, we'll do a simple spatial transformation in order to give you a sense of how much area it covers.\n",
    "\n",
    "But first, here is a bit of an exploration of the GeoJSON format. Once imported, you'll note that its a Polygon, and it's basically a rectanglar area in geographic coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ac93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_metro = open_geojson('./' + paths['iDir'] + 'twin_cities_metro.geojson')\n",
    "tc_metro['features']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1e7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_bounds = get_geojson_geometry(tc_metro)\n",
    "tc_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d0cef",
   "metadata": {},
   "source": [
    "#### Convert the GeoJSON to GeoDataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85066698",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = gpd.GeoDataFrame({'name' : ['Twin Cities Metro']}, geometry = [Polygon(tc_bounds[0]['coordinates'][0])], crs = 4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8174bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi.explore(color='blue', style_kwds={'stroke': True, 'fill': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdcf074",
   "metadata": {},
   "source": [
    "Let's be a bit quantitative and get an idea of the actual dimensions we are looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5273b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_utm = aoi.to_crs(32615)\n",
    "aoi_utm.area[0] /1000**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16042f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = (aoi_utm.bounds['maxx'][0] - aoi_utm.bounds['minx'][0]) / 1000\n",
    "width = (aoi_utm.bounds['maxy'][0] - aoi_utm.bounds['miny'][0]) / 1000\n",
    "print(f'length: {length}')\n",
    "print(f'width: {width}')\n",
    "print(f'area: {length * width}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9349c",
   "metadata": {},
   "source": [
    "### Pause to consider: Magnitude of the area vs amount of available data\n",
    "efore we get into the actual querrying and filtering aspect of working with the AOI, we really do want you to pause and consider that area above. The area for our study is ~$9,480 km^{2}$. Let's just round up and call it $10,000 km^{2}$.\n",
    "\n",
    "The reason this notebook exits, is to help you understand the importance of filtering data down to managable sizes. Using the query and the data we're going to work with in a few minutes, is entirely possibly to download $10x$ the required area using a single day's worth of imagery.\n",
    "\n",
    "Yes, that is right. Without filtering down the data, you can without much trouble, end up with $~ 100,000 km^{2}$ of data. of which you didn't really need. Not only do you not need it, queries like this can consume significant amounts of UMN's quota. We ask that you be conscious of that when ordering data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404634b",
   "metadata": {},
   "source": [
    "### Query details\n",
    "\n",
    "#### Geometry\n",
    "```\n",
    "geojson_geometry = tc_bounds[0]\n",
    "# get images that overlap with our AOI \n",
    "geo_filter = {\n",
    "  \"type\": \"GeometryFilter\",\n",
    "  \"field_name\": \"geometry\",\n",
    "  \"config\": geojson_geometry\n",
    "}\n",
    "```\n",
    "\n",
    "#### Date & time\n",
    "```\n",
    "# get images acquired within a date range\n",
    "date_filter = {\n",
    "  \"type\": \"DateRangeFilter\",\n",
    "  \"field_name\": \"acquired\",\n",
    "  \"config\": {\n",
    "    \"gte\": \"2021-06-12T00:00:00.000Z\",\n",
    "    \"lte\": \"2021-06-13T00:00:00.000Z\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Cloud filter\n",
    "```\n",
    "cc_filter = {\n",
    "  \"type\": \"RangeFilter\",\n",
    "  \"field_name\": \"cloud_cover\",\n",
    "  \"config\": {\n",
    "    \"lte\": 0.0\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Combined filter\n",
    "```\n",
    "# combine our geo, date, cloud filters\n",
    "combined_filter = {\n",
    "  \"type\": \"AndFilter\",\n",
    "  \"config\": [geo_filter, date_filter, cc_filter]\n",
    "}\n",
    "```\n",
    "\n",
    "#### Item/ Asset Filters\n",
    "```\n",
    "item_type = \"PSScene\"\n",
    "# API request object\n",
    "search_request = {\n",
    "  \"item_types\": [item_type], \n",
    "  \"filter\": combined_filter\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bf6046",
   "metadata": {},
   "source": [
    "### Search query\n",
    "```\n",
    "search_result = \\\n",
    "  requests.post(\n",
    "    'https://api.planet.com/data/v1/quick-search',\n",
    "    auth=HTTPBasicAuth(PLANET_API_KEY, ''),\n",
    "    json=search_request)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e787f41",
   "metadata": {},
   "source": [
    "### Load the search results\n",
    "\n",
    "The query above was run in advance for you. Now, let's have a look at it. As before, it won't be super useful in this format. So we'll go through the process of transforming it as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/large_area_query.json', 'r', encoding='utf-8') as f:\n",
    "    results_json = json.load(f)\n",
    "\n",
    "results_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa033e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = pd.json_normalize(results_json['features'], max_level=1)\n",
    "\n",
    "# rename properties column, dropping the properties label\n",
    "prop_cols = {col: col.split('.')[1] for col in tiles.columns if 'properties' in col}\n",
    "tiles.rename(columns=prop_cols, inplace=True)\n",
    "tiles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c436b47d",
   "metadata": {},
   "source": [
    "### Note\n",
    "This notebook was originally developed, in part, because cloud filtering turned out not to be useful on this partiulcar day. Note above the cloud filter is quite agressisve less than or equal to .0. Relaxing this constraint to allow for 50% cloud cover will not result in fewer tiles being identified. \n",
    "\n",
    "This is an important difference between _constillations sensor_ of satellites and single platform sensors. Between days, cloud cover varies significantly. Within a given day, cloud cover can vary, but sometime it doesn't vary much at all. That is what you are seeing here - this was a very clear day across the Cities!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9371441",
   "metadata": {},
   "source": [
    "### Geodataframe\n",
    "The GeoDataFrame will look similar to the DataFrame, but in this case a geometry column and a `centroids` column have been added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db97b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms = [Polygon(geo[0]) for geo in tiles['geometry.coordinates']]\n",
    "tiles = gpd.GeoDataFrame(tiles, geometry = geoms, crs=4326)\n",
    "tiles['centroids'] = tiles['geometry'].centroid\n",
    "tiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf57cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles.set_geometry('geometry', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5128f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = tiles.explore( color ='orange', style_kwds={'stroke': True, 'fill': False})\n",
    "aoi.explore( color= 'blue', m = ax, style_kwds={'stroke': True, 'fill': False})\n",
    "tiles['geometry'].centroid.explore(color='k', m =ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9da231",
   "metadata": {},
   "source": [
    "That's a very busy, image. So let's take a bit of time to examine it, and look at some details more closely and discuss them.\n",
    "\n",
    "First, the tile foot prints are larger than the AOI. The Planet API geometry filter uses an `intersection` for the geometry, meaning it will return any tile that touches the AOI. It would be nice if they supported other spatial operations, but they don't. Filtering using other spatial operations has to be done on the user side.\n",
    "\n",
    "You may note that the figure is really busy. If you realized that there are a number of different sized tiles in that figure you are right. Though the data are in geographic cooridnate (and hence the `.area` method will spit out a warning, we can get a sense of the relative size differences in the footprints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10341ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_area = tiles['geometry'].area\n",
    "tile_area.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f084002",
   "metadata": {},
   "source": [
    "Though the units are not helpful, we can see that tiles vary by factors of\n",
    "$2x$ and $4x$ . We can use that basic information to look at those differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2682642",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = aoi.explore( color= 'blue', m = ax, style_kwds={'stroke': True, 'fill': False})\n",
    "# biggest tiles first\n",
    "idx = tiles['geometry'].area >= 0.079\n",
    "tiles.loc[idx].explore( color='orange', m = ax, style_kwds={'stroke': True, 'fill': False})\n",
    "\n",
    "# medium tiles next\n",
    "idx = ((tiles['geometry'].area >= 0.04) & (tiles['geometry'].area < 0.079) )\n",
    "tiles.loc[idx].explore(color='green', m = ax, style_kwds={'stroke': True, 'fill': False})\n",
    "\n",
    "# small tiles next\n",
    "idx = (tiles['geometry'].area < 0.04) \n",
    "tiles.loc[idx].explore( color='black', m = ax, style_kwds={'stroke': True, 'fill': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf90a9a",
   "metadata": {},
   "source": [
    "AOI is in blue still, the larger tiles are in orange, the smallest in grey, and the medim tiles are in green. These differences in footprint likely correspond with different generations of Planet sensor constillations. This figure makes it clear, there are not as many of the medium resoltuion foot prints, and the sensor with the smaller foot prints. Neither the small nor medium has a good spatial coverage of the AOI.\n",
    "\n",
    "This suggests that the area of the footprint can be used to filter this list down! Even though the units are not meaningful ($decimal degrees ^{2}) they still provide a relative sense of area that we can use to filter the list down.\n",
    "\n",
    "Let's do that now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb778994",
   "metadata": {},
   "source": [
    "### Constillation sensor type\n",
    "Before filtering based on tile footprint, it's worth discussing the reason for these footprint differences. As noted above, Planet operates constillations of satellites. Over time, they have improved their sensor platforms. Some of these changes include increased radiometric performance (allowing sensor values to be comperable between individual sensors within the constillation family), some have increased the number of spectral bands (allowing for increased discrimination of land cover types), and other changes have changed the band-pass characteristics (allowing for better comparison with other satellite platforms, such as Landsat and Sentinel).\n",
    "\n",
    "Improvements in some sensor characteristics often invovles a trade off with other characteristics, and trading off tile footprint. Footprint is a function of the instanteous field of view IFOVof the sensor. So, before moving on, let's have a look at the different sensor types with the images returned in this query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdd3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = set(tiles['instrument'])\n",
    "instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['orange', 'green', [.4,.4,.4] ]\n",
    "\n",
    "for instrument, color in zip(instruments,colors):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15,15))\n",
    "\n",
    "    aoi.plot(facecolor='none', edgecolor='blue', linewidth = 2, ax = ax)\n",
    "    plot_wrapper(tiles[tiles.instrument == instrument], ax = ax, color=color)\n",
    "    fig.suptitle(f'Tile footprints for sensor type: {instrument}', fontsize=20)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18564d24",
   "metadata": {},
   "source": [
    "We can see there is a relationship between tile footprint and sensor generation, so let's have a quick look at what the 'area' of each tile footprint is for each sensor type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf5c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "for instrument in instruments:\n",
    "    print(f'instrument type: {instrument}')\n",
    "    print(tiles[tiles.instrument==instrument].area)\n",
    "    print(f'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119846e4",
   "metadata": {},
   "source": [
    "### Examine the `PSB.SD` sensors, AKA 'largerest' tiles to start\n",
    "\n",
    "We could use tile size directly, and an early version of this Notebook did just that. The relationship between footprint and instrument type are pretty clear. If you understand that relationship, you can use it to your advantage. Maybe you want only the largest footprints for a given sensor type. Understanding your study needs may point you in a particular direction.\n",
    "\n",
    "Here, we're going to use the relationship between sensor type and footprint to select the largest tiles. In addition to having a relationship with footprint, there are good reasons filter on instument type. As noted above, [sensors have improved over time](https://earth.esa.int/eogateway/documents/20142/37627/Planet-combined-imagery-product-specs-2020.pdf), and those improvements have led to better radiomentric image quality in particular. It is worth making an [effort to understand sensor characteristcs](https://www.mdpi.com/2072-4292/13/19/3930), as this can have a large impact on the quality and veracity of your study results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb584f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles.set_geometry('geometry', inplace=True)\n",
    "# idx = tiles['geometry'].area >= 0.079\n",
    "\n",
    "larger_tiles = tiles[tiles['instrument']=='PSB.SD']\n",
    "larger_tiles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0075c553",
   "metadata": {},
   "source": [
    "You'll note that we've now cut the list of tiles down by more than half! We're down to $41$ tiles from $93$. It's a good start. We can also visualize the new set. In doing so, we'll see we've removed much of the spatial duplication that was there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15,15))\n",
    "\n",
    "aoi.plot(facecolor='none', edgecolor='blue', linewidth = 2, ax = ax)\n",
    "larger_tiles.plot(facecolor='none', edgecolor='orange', ax = ax)\n",
    "larger_tiles['geometry'].centroid.plot(color='k', ax =ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441243db",
   "metadata": {},
   "source": [
    "You can see that the overlap between tiles is not uniform across the AOI, but it's better than it was. There is considerable overlap in tiles along the left hand edge of the AOI. Before we move on to ways to refine the filtering futher, I want to focus briefly on what Planet calls `Products` and what they call `Assets`.\n",
    "\n",
    "Above, when we querried the API, we specifically asked for Planet's `PSScene` product. The section of code was:\n",
    "\n",
    "```\n",
    "item_type = \"PSScene\"\n",
    "# API request object\n",
    "search_request = {\n",
    "  \"item_types\": [item_type], \n",
    "  \"filter\": combined_filter\n",
    "}\n",
    "```\n",
    "Most University license agreement with Planet gives us access to to Planet products `PSScence` and `Basemap`. `PSScence` represent their imagery products. The `Basemap` product is built from the `PSScence` imagery, and is basically a composited product. That is, the `Basemap` is basically a composit of all the best images captured during the time period in question. Our license agreement gives us access to both their monthly and quartery `Basemap` composites. In the terminology of Planet's API, those quarterly and monthly `Basemaps` are referred to as `Assets`.\n",
    "\n",
    "Planet `Assets` are basically a sub-type of the `Product` class, that have particular characteristics. For the `Basemap` product, charcteristics of the `Assets` is reasonably self evident: the monthly `Basemap Asset` is a composite product that represents the best imagery from the month in question (e.g. June 2021) and the quarterly `Basemap Asset` that covers the June 2021 period would be composed of images captured between April - June 2021.\n",
    "\n",
    "So, with that in mind, let's look at how many Planet Assets there are for some of the PSScene tiles we asked the API to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381288a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles.loc[0]['assets'], tiles.loc[34]['assets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1f0ac",
   "metadata": {},
   "source": [
    "The two lists are not the same, but that is ok. The images come from two different generations of constillations. The first one is from their SuperDove constilation, which has 8 spectral bands (e.g. `ortho_analytic_8b_sr`, and the second is from an older generation, as it only has data from up to 4 bands `ortho_analytic_4b_sr`).\n",
    "\n",
    "To help manage the fact that there are sensors with different numbers of bands, backwards compatability is maintened by the fact that you can basically get the 4 band subset (red, green, blue, NIR) from the newer 8 band constillation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119abfc",
   "metadata": {},
   "source": [
    "### Filtering take away :\n",
    "\n",
    "The focus of this part is on filtering the number of tiles down. As part of this discussion, it's important to recognize that within the single `PSScence` product, there are a number different `Asset` types. Knowing which specific `Asset` type you are after is important, as if you download multiple Assets each individual Asset counts against the U of M Tile Download Quota.\n",
    "\n",
    "So you can see, it not hard to end up with significantly more data than you need, and much of it will be redundant! For example, using the 8-band constilation, if you downloaded both the `ortho_analytic_4b_sr` and `ortho_analytic_8b_sr` `Assets` half of your data will be duplicates!\n",
    "\n",
    "For most quantitative analyses, the suggestion would be to work with either the `PSScence` `ortho_analytic_4b_sr` or `ortho_analytic_8b_sr` `Asset`, denending on your needs. If you are looking back in time, understand that the 8-band sensors have only come online in recent years, and that the further back in time you search, you're most likely to find older generations of the 4-band sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae39ca65",
   "metadata": {},
   "source": [
    "### Back to filtering\n",
    "If you look back to the last image, you'll note that a number of the image tiles don't have centroids that fall within the AOI. You'll also note that those with centroids within the AOI tend to make up more of the area within the AOI.\n",
    "\n",
    "This suggests we can use the spatial operation `within` as a way to filterdown the tile list further. So let's do that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652d535",
   "metadata": {},
   "source": [
    "###  start with tiles with centroids contained by AOI\n",
    "\n",
    "These will be tiles with more useable foot print areas within the AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68517d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_tiles.set_geometry('centroids', inplace=True)\n",
    "# tiles_centroids_contained = gpd.sjoin(tiles, aoi , how ='inner', op='within')\n",
    "# tiles_centroids_contained = aoi.sjoin(tiles, how ='right', predicate='contains')\n",
    "lt_centroids_contained = gpd.sjoin(larger_tiles, aoi, how='inner', predicate='within' )\n",
    "lt_centroids_contained.set_geometry('geometry', inplace=True)\n",
    "lt_centroids_contained.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f166dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15,15))\n",
    "\n",
    "aoi.plot(facecolor='none', edgecolor='blue', linewidth = 2, ax = ax)\n",
    "lt_centroids_contained.plot(facecolor='none', edgecolor='orange', ax = ax)\n",
    "lt_centroids_contained['geometry'].centroid.plot(color='k', ax =ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbbb57d",
   "metadata": {},
   "source": [
    "So, you can see, we have a smaller set that comes close to being what we need. We see that there is still more area outside the AOI then we really want, but that is ok! Part of the Planet API functionality does include the ability to clip tiles using the AOI before are downloaded. We'll focus on that later in the Notebook.\n",
    "\n",
    "\n",
    "### the contained centroids form basis of our 'to_download_set'\n",
    "\n",
    "we'll make a copy to be on the safe side. we'll then append to this set using the areas not covered by these tiles shortly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ba35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_download = larger_tiles.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c08219",
   "metadata": {},
   "source": [
    "### get larger tiles with centroid that are not contained\n",
    "\n",
    "For now, let's look at the tiles with centroids not contained by the AOI. Clearly, if we want a complete AOI, we'll need to add some of them to our tile list. They will be needed to fill out the gaps around the edges of the AOI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ea3961",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_centroid_not_contained = larger_tiles[~larger_tiles.index.isin(lt_centroids_contained.index)]\n",
    "lt_centroid_not_contained.set_geometry('geometry', inplace=True)\n",
    "lt_centroid_not_contained.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a4e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15,15))\n",
    "\n",
    "aoi.plot(facecolor='none', edgecolor='blue', linewidth = 2, ax = ax)\n",
    "lt_centroid_not_contained.plot(facecolor='none', edgecolor='green', ax = ax)\n",
    "lt_centroid_not_contained['geometry'].centroid.plot(color='k', ax =ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6e570a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "So, we have a list of tiles we know we are going to use (those with centroids within the AOI) and a list of candidates to choose to include to fill out the edges. How to proceed next? Basically, we're going to leverage the geometry of the tiles with contained centroids. We will use those tiles to figure out which areas we need to fill.\n",
    "\n",
    "We'll then use the 'blank areas' that we need to fill to find the tiles whose centroids were not contained by the AOI to identify the candiates for filling. We'll then iterate through the tiles that touch each 'blank area' to see how much of their gemetry fills the blank. Once part of the blank is filled, we'll continue until there are no tiles, or no blank left to fill!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1fe503",
   "metadata": {},
   "source": [
    "###  use the geometry of contained centroids\n",
    "\n",
    "now we'll use the geometry of the larger tiles to identify areas with no coverage in the AOI we'll start by creating a copy the larger tiles geodataframe, then we'll disolve the geomety into a single shape. we'll then clip the disolved shape using the AOI, and then use the geopandas difference to find areas not covered by the contained centroid tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab8a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_disolved = lt_centroids_contained.copy()\n",
    "lt_disolved = lt_disolved.dissolve()\n",
    "lt_disolved = lt_disolved.clip(aoi)\n",
    "lt_disolved.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_missing = aoi.difference(lt_disolved)\n",
    "aoi_missing.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47460998",
   "metadata": {},
   "source": [
    "What we end up with is a MultiPolygon that has all of the areas that we need to fill. There are several parts, all of differing sizes.\n",
    "\n",
    "If you're not familiar with a MutliPolygon, it is basically a Polygon that is made up of different Polygons. They can be complciated (think of a doughnut) but in this case, thankfully it's not complicated. We can use the `.explode` method to break that MultiPolygon into it's parts, then iterate though them piece by piece.\n",
    "\n",
    "### use the parts of the resulting missing multi-polygon to identify intersecting tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_miss_parts = aoi_missing.explode()\n",
    "aoi_miss_parts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da0e124",
   "metadata": {},
   "source": [
    "###  loop through the missing part areas to find larger tiles with centroids that were not contained that intersect the missing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_tile_ids =[]\n",
    "for i in range(aoi_miss_parts.shape[0]):\n",
    "    poly = aoi_miss_parts[0,i]\n",
    "#     t = gpd.overlay(lt_centroid_not_contained, mp, how = 'intersection')\n",
    "    ix = lt_centroid_not_contained.intersects(poly, align=False)\n",
    "    \n",
    "    t = lt_centroid_not_contained.loc[ix].copy()\n",
    "    t = t.clip(poly)\n",
    "    t['area'] = t['geometry'].area\n",
    "    t.sort_values('area', ascending=False, inplace=True)\n",
    "    \n",
    "    for i,r in t.iterrows():\n",
    "        \n",
    "        if poly.is_empty:\n",
    "            break \n",
    "            \n",
    "        additional_tile_ids.append(r['id'])\n",
    "        poly = poly.difference(r['geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b2440",
   "metadata": {},
   "source": [
    "Now that we've done the processing, let's see how many additional tiles it will take to fill in the blanks. For comparison, we'll also look at the original number of tiles with centroids that we not contained by the AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e038bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_tile_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f58325",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(additional_tile_ids), lt_centroid_not_contained.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a9c07",
   "metadata": {},
   "source": [
    "So, we've saved ourself 9 tiles that we didn't need. Though some of the area taken up by those tiles is not large, we will also save ourselves the hassel of downloading duplicated data too, which is a win.\n",
    "\n",
    "###  combine and visualize\n",
    "\n",
    "As a last step, we'll use the additional_tile_ids list to add the tile to our\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_download = larger_tiles[larger_tiles.index.isin(lt_centroids_contained.index)].copy()\n",
    "to_download = pd.concat([to_download,larger_tiles[larger_tiles.id.isin(additional_tile_ids)]])\n",
    "to_download.set_geometry('geometry', inplace=True)\n",
    "to_download.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15,15))\n",
    "\n",
    "aoi.plot(facecolor='none', edgecolor='blue', linewidth = 2, ax = ax)\n",
    "to_download.plot(facecolor='none', edgecolor='orange', ax = ax)\n",
    "to_download['geometry'].centroid.plot(color='k', ax =ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23170f67",
   "metadata": {},
   "source": [
    "We now have a list of 31 one tiles that can be used to represent the AOI. Although there isn't time today, ordering tiles is straightforward, and there are good resouces on how to do that. It's also worth noting that we could use Planet's `tool chain` to `clip` those  images down, so that all we get is just the area within the TC AOI. Their `tool chain` contains other useful image processing tools that might also be of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe39f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f90d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iaa-analytics",
   "language": "python",
   "name": "iaa-analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
